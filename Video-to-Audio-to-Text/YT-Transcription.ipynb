{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: brew\n"
     ]
    }
   ],
   "source": [
    "!brew install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/ffmpeg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add the directory containing ffmpeg to the PATH in the notebook\n",
    "os.environ['PATH'] += os.pathsep + '/usr/local/bin'\n",
    "\n",
    "# Check if ffmpeg is now recognized\n",
    "!which ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/ffprobe\n"
     ]
    }
   ],
   "source": [
    "!which ffprobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import environ\n",
    "import yt_dlp\n",
    "import openai\n",
    "from pydub import AudioSegment\n",
    "from pyannote.audio import Pipeline\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Set your OpenAI API key\n",
    "client.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Hugging Face API key\n",
    "HF_API_Key = os.environ[\"HF_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    " # Specify the location of ffmpeg\n",
    "        'ffmpeg_location': '/usr/local/bin/ffmpeg',  # Use the path found via `which ffmpeg`\n",
    "        'outtmpl': output_file\n",
    "```        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=4YWAZEcYeMQ\n",
      "[youtube] 4YWAZEcYeMQ: Downloading webpage\n",
      "[youtube] 4YWAZEcYeMQ: Downloading ios player API JSON\n",
      "[youtube] 4YWAZEcYeMQ: Downloading web creator player API JSON\n",
      "[youtube] 4YWAZEcYeMQ: Downloading m3u8 information\n",
      "[info] 4YWAZEcYeMQ: Downloading 1 format(s): 251\n",
      "[download] Destination: AI Doom Debate： Tilek Mamutov vs. Liron Shapira.webm\n",
      "[download] 100% of   81.22MiB in 00:00:04 at 19.54MiB/s    \n",
      "[ExtractAudio] Destination: AI Doom Debate： Tilek Mamutov vs. Liron Shapira.wav\n",
      "Deleting original file AI Doom Debate： Tilek Mamutov vs. Liron Shapira.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/7.0.2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[aist#0:0/pcm_s16le @ 0x7fa9fef07a00] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'AI Doom Debate： Tilek Mamutov vs. Liron Shapira.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 01:44:38.54, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'AI Doom Debate： Tilek Mamutov vs. Liron Shapira_16khz_mono.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "[out#0/wav @ 0x7fa9fef082c0] video:0KiB audio:196204KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000039%\n",
      "size=  196204KiB time=01:44:38.53 bitrate= 256.0kbits/s speed=1.28e+03x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: AI Doom Debate： Tilek Mamutov vs. Liron Shapira_16khz_mono.wav\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=NdgPOXWU864\n",
      "[youtube] NdgPOXWU864: Downloading webpage\n",
      "[youtube] NdgPOXWU864: Downloading ios player API JSON\n",
      "[youtube] NdgPOXWU864: Downloading web creator player API JSON\n",
      "[youtube] NdgPOXWU864: Downloading m3u8 information\n",
      "[info] NdgPOXWU864: Downloading 1 format(s): 251\n",
      "[download] Destination: AI Doom Debate - Liron Shapira vs. Mikael Koivukangas.webm\n",
      "[download] 100% of   45.68MiB in 00:00:02 at 20.48MiB/s    \n",
      "[ExtractAudio] Destination: AI Doom Debate - Liron Shapira vs. Mikael Koivukangas.wav\n",
      "Deleting original file AI Doom Debate - Liron Shapira vs. Mikael Koivukangas.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/7.0.2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[aist#0:0/pcm_s16le @ 0x7fcdb4f05dc0] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'AI Doom Debate - Liron Shapira vs. Mikael Koivukangas.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 00:53:03.04, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'AI Doom Debate - Liron Shapira vs. Mikael Koivukangas_16khz_mono.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "size=   77824KiB time=00:41:34.12 bitrate= 255.6kbits/s speed= 989x        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: AI Doom Debate - Liron Shapira vs. Mikael Koivukangas_16khz_mono.wav\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=R3_vh00p-x8\n",
      "[youtube] R3_vh00p-x8: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/wav @ 0x7fcdb58210c0] video:0KiB audio:99470KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000077%\n",
      "size=   99470KiB time=00:53:03.04 bitrate= 256.0kbits/s speed=1.03e+03x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] R3_vh00p-x8: Downloading ios player API JSON\n",
      "[youtube] R3_vh00p-x8: Downloading web creator player API JSON\n",
      "[youtube] R3_vh00p-x8: Downloading m3u8 information\n",
      "[info] R3_vh00p-x8: Downloading 1 format(s): 251\n",
      "[download] Destination: AI Doom Debate： Liron Shapira vs. Alexander Campbell.webm\n",
      "[download] 100% of   36.82MiB in 00:00:02 at 14.39MiB/s    \n",
      "[ExtractAudio] Destination: AI Doom Debate： Liron Shapira vs. Alexander Campbell.wav\n",
      "Deleting original file AI Doom Debate： Liron Shapira vs. Alexander Campbell.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/7.0.2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[aist#0:0/pcm_s16le @ 0x7fa28ab0c800] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'AI Doom Debate： Liron Shapira vs. Alexander Campbell.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 00:46:19.94, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'AI Doom Debate： Liron Shapira vs. Alexander Campbell_16khz_mono.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "size=   64512KiB time=00:34:30.18 bitrate= 255.3kbits/s speed=1.37e+03x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: AI Doom Debate： Liron Shapira vs. Alexander Campbell_16khz_mono.wav\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=lt4vR6XQk-o\n",
      "[youtube] lt4vR6XQk-o: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/wav @ 0x7fa28ab0c980] video:0KiB audio:86873KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000088%\n",
      "size=   86873KiB time=00:46:19.93 bitrate= 256.0kbits/s speed=1.37e+03x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] lt4vR6XQk-o: Downloading ios player API JSON\n",
      "[youtube] lt4vR6XQk-o: Downloading web creator player API JSON\n",
      "[youtube] lt4vR6XQk-o: Downloading m3u8 information\n",
      "[info] lt4vR6XQk-o: Downloading 1 format(s): 251\n",
      "[download] Destination: George Hotz and Liron Shapira debate AI doom.webm\n",
      "[download] 100% of   56.88MiB in 00:00:03 at 15.83MiB/s    \n",
      "[ExtractAudio] Destination: George Hotz and Liron Shapira debate AI doom.wav\n",
      "Deleting original file George Hotz and Liron Shapira debate AI doom.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/7.0.2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[aist#0:0/pcm_s16le @ 0x7fbc0b011e00] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'George Hotz and Liron Shapira debate AI doom.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 01:14:42.98, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'George Hotz and Liron Shapira debate AI doom_16khz_mono.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "[out#0/wav @ 0x7fbc0b013e40] video:0KiB audio:140093KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000054%\n",
      "size=  140093KiB time=01:14:42.98 bitrate= 256.0kbits/s speed= 962x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: George Hotz and Liron Shapira debate AI doom_16khz_mono.wav\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=dTQb6N3_zu8\n",
      "[youtube] dTQb6N3_zu8: Downloading webpage\n",
      "[youtube] dTQb6N3_zu8: Downloading ios player API JSON\n",
      "[youtube] dTQb6N3_zu8: Downloading web creator player API JSON\n",
      "[youtube] dTQb6N3_zu8: Downloading m3u8 information\n",
      "[info] dTQb6N3_zu8: Downloading 1 format(s): 251\n",
      "[download] Destination: Robin Hanson vs. Liron Shapira： Is Near-Term Extinction From AGI Plausible？.webm\n",
      "[download] 100% of   97.54MiB in 00:00:05 at 17.60MiB/s    \n",
      "[ExtractAudio] Destination: Robin Hanson vs. Liron Shapira： Is Near-Term Extinction From AGI Plausible？.wav\n",
      "Deleting original file Robin Hanson vs. Liron Shapira： Is Near-Term Extinction From AGI Plausible？.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/7.0.2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[aist#0:0/pcm_s16le @ 0x7fb286d07440] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'Robin Hanson vs. Liron Shapira： Is Near-Term Extinction From AGI Plausible？.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 02:08:35.40, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'Robin Hanson vs. Liron Shapira： Is Near-Term Extinction From AGI Plausible？_16khz_mono.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "[out#0/wav @ 0x7fb286d07300] video:0KiB audio:241106KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000032%\n",
      "size=  241106KiB time=02:08:35.39 bitrate= 256.0kbits/s speed=1.07e+03x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Robin Hanson vs. Liron Shapira： Is Near-Term Extinction From AGI Plausible？_16khz_mono.wav\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=f71yn1j5Uyc\n",
      "[youtube] f71yn1j5Uyc: Downloading webpage\n",
      "[youtube] f71yn1j5Uyc: Downloading ios player API JSON\n",
      "[youtube] f71yn1j5Uyc: Downloading web creator player API JSON\n",
      "[youtube] f71yn1j5Uyc: Downloading m3u8 information\n",
      "[info] f71yn1j5Uyc: Downloading 1 format(s): 251\n",
      "[download] Destination: AI Foom Debate： Liron Shapira vs. Beff Jezos (e⧸acc) on Sep 1, 2023.webm\n",
      "[download] 100% of  225.71MiB in 00:00:10 at 21.86MiB/s    \n",
      "[ExtractAudio] Destination: AI Foom Debate： Liron Shapira vs. Beff Jezos (e⧸acc) on Sep 1, 2023.wav\n",
      "Deleting original file AI Foom Debate： Liron Shapira vs. Beff Jezos (e⧸acc) on Sep 1, 2023.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/7.0.2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[aist#0:0/pcm_s16le @ 0x7fef6800bf00] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'AI Foom Debate： Liron Shapira vs. Beff Jezos (e⧸acc) on Sep 1, 2023.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 03:51:16.96, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'AI Foom Debate： Liron Shapira vs. Beff Jezos (e⧸acc) on Sep 1, 2023_16khz_mono.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "[out#0/wav @ 0x7fef6800be00] video:0KiB audio:433655KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000018%\n",
      "size=  433655KiB time=03:51:16.96 bitrate= 256.0kbits/s speed=1.01e+03x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: AI Foom Debate： Liron Shapira vs. Beff Jezos (e⧸acc) on Sep 1, 2023_16khz_mono.wav\n",
      "All videos processed!\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "urls = [\n",
    "        \"https://www.youtube.com/watch?v=4YWAZEcYeMQ\", # Tilek Mamutov\n",
    "        \"https://www.youtube.com/watch?v=NdgPOXWU864\", # Mikael Koivukangas\n",
    "        \"https://www.youtube.com/watch?v=R3_vh00p-x8\", # Alexander Campbell\n",
    "        \"https://www.youtube.com/watch?v=lt4vR6XQk-o\", # George Hotz Spaces on X\n",
    "        \"https://www.youtube.com/watch?v=dTQb6N3_zu8\", # Robin Hanson\n",
    "        \"https://www.youtube.com/watch?v=f71yn1j5Uyc\" # Beff Jezos Spaces on X\n",
    "    ]\n",
    "\n",
    "def download_and_convert(url):\n",
    "    try:\n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'postprocessors': [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'wav',\n",
    "            }],\n",
    "            'outtmpl': '%(title)s.%(ext)s',\n",
    "        }\n",
    "\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            info = ydl.extract_info(url, download=True)\n",
    "            filename = ydl.prepare_filename(info).replace('.webm', '.wav')\n",
    "\n",
    "        # Convert to 16kHz mono\n",
    "        output_filename = f\"{os.path.splitext(filename)[0]}_16khz_mono.wav\"\n",
    "        cmd = [\n",
    "            \"ffmpeg\",\n",
    "            \"-i\", filename,\n",
    "            \"-ar\", \"16000\",\n",
    "            \"-ac\", \"1\",\n",
    "            \"-c:a\", \"pcm_s16le\",\n",
    "            output_filename\n",
    "        ]\n",
    "        subprocess.run(cmd, check=True)\n",
    "\n",
    "        # Clean up original WAV file\n",
    "        os.remove(filename)\n",
    "\n",
    "        print(f\"Processed: {output_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {url}: {str(e)}\")\n",
    "\n",
    "for url in urls:\n",
    "    download_and_convert(url)\n",
    "\n",
    "print(\"All videos processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (1.40.0)\n",
      "Requirement already satisfied: pyannote.audio in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (3.3.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from openai) (4.66.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: asteroid-filterbanks>=0.4 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (0.4.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (0.8.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (0.20.2)\n",
      "Requirement already satisfied: lightning>=2.0.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (2.3.0)\n",
      "Requirement already satisfied: pyannote.core>=5.0.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (5.0.0)\n",
      "Requirement already satisfied: pyannote.database>=5.0.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (5.1.0)\n",
      "Requirement already satisfied: pyannote.metrics>=3.2 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (3.2.1)\n",
      "Requirement already satisfied: pyannote.pipeline>=3.0.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (3.0.1)\n",
      "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (2.6.0)\n",
      "Requirement already satisfied: rich>=12.0.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (13.7.0)\n",
      "Requirement already satisfied: semver>=3.0.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (3.0.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (0.12.1)\n",
      "Requirement already satisfied: speechbrain>=1.0.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (1.0.0)\n",
      "Requirement already satisfied: tensorboardX>=2.6 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (2.6.2.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (2.2.2)\n",
      "Requirement already satisfied: torch-audiomentations>=0.11.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (0.11.1)\n",
      "Requirement already satisfied: torchaudio>=2.2.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (2.2.2)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.audio) (1.4.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: numpy in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from asteroid-filterbanks>=0.4->pyannote.audio) (1.24.3)\n",
      "Requirement already satisfied: certifi in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2023.10.0)\n",
      "Requirement already satisfied: requests in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (2.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from huggingface-hub>=0.13.0->pyannote.audio) (23.1)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from lightning>=2.0.1->pyannote.audio) (0.11.6)\n",
      "Requirement already satisfied: pytorch-lightning in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from lightning>=2.0.1->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.core>=5.0.0->pyannote.audio) (1.11.2)\n",
      "Requirement already satisfied: pandas>=0.19 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.1.4)\n",
      "Requirement already satisfied: typer>=0.12.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.database>=5.0.1->pyannote.audio) (0.12.4)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.4.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.6.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.9.1.post1)\n",
      "Requirement already satisfied: sympy>=1.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.12)\n",
      "Requirement already satisfied: optuna>=3.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pyannote.pipeline>=3.0.1->pyannote.audio) (3.6.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from rich>=12.0.0->pyannote.audio) (2.18.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from soundfile>=0.12.1->pyannote.audio) (1.16.0)\n",
      "Requirement already satisfied: hyperpyyaml in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from speechbrain>=1.0.0->pyannote.audio) (1.2.2)\n",
      "Requirement already satisfied: joblib in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from speechbrain>=1.0.0->pyannote.audio) (1.3.2)\n",
      "Requirement already satisfied: sentencepiece in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from speechbrain>=1.0.0->pyannote.audio) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from tensorboardX>=2.6->pyannote.audio) (4.24.0)\n",
      "Requirement already satisfied: networkx in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from torch>=2.0.0->pyannote.audio) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from torch>=2.0.0->pyannote.audio) (3.1.3)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.2.7)\n",
      "Requirement already satisfied: librosa>=0.6.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.10.2.post1)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (1.2.4)\n",
      "Requirement already satisfied: pycparser in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.21)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (3.9.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (3.0.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.59.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.4.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (1.0.8)\n",
      "Requirement already satisfied: setuptools in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.0.1->pyannote.audio) (68.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (2.8.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.13.2)\n",
      "Requirement already satisfied: colorlog in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (6.8.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.25)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from sympy>=1.1->pyannote.metrics>=3.2->pyannote.audio) (1.3.0)\n",
      "Requirement already satisfied: primePy>=1.3 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio) (1.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.18.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->pyannote.audio) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13.0->pyannote.audio) (2.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface-hub>=0.13.0->pyannote.audio) (1.3.1)\n",
      "Requirement already satisfied: Mako in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.3.5)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (3.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.16.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote.audio) (0.2.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/shylaatchison/opt/anaconda3/envs/standard/lib/python3.11/site-packages (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai pyannote.audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not download 'pyannote/speaker-diarization' pipeline.\n",
      "It might be because the pipeline is private or gated so make\n",
      "sure to authenticate. Visit https://hf.co/settings/tokens to\n",
      "create your access token and retry with:\n",
      "\n",
      "   >>> Pipeline.from_pretrained('pyannote/speaker-diarization',\n",
      "   ...                          use_auth_token=YOUR_AUTH_TOKEN)\n",
      "\n",
      "If this still does not work, it might be because the pipeline is gated:\n",
      "visit https://hf.co/pyannote/speaker-diarization to accept the user conditions.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OpenAI' object has no attribute 'Audio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscription saved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtranscription_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 58\u001b[0m     \u001b[43mprocess_wav_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 50\u001b[0m, in \u001b[0;36mprocess_wav_files\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     47\u001b[0m audio_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, file_name)\n\u001b[1;32m     48\u001b[0m transcription_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(audio_file_path)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_transcription.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 50\u001b[0m transcription_text \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_audio_with_speaker_diarization\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(transcription_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     53\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(transcription_text)\n",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m, in \u001b[0;36mtranscribe_audio_with_speaker_diarization\u001b[0;34m(audio_file_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranscribe_audio_with_speaker_diarization\u001b[39m(audio_file_path):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Perform transcription using OpenAI's Whisper\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(audio_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m audio_file:\n\u001b[0;32m---> 24\u001b[0m         transcript \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAudio\u001b[49m\u001b[38;5;241m.\u001b[39mtranscribe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhisper-1\u001b[39m\u001b[38;5;124m\"\u001b[39m, audio_file)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Perform speaker diarization using pyannote.audio\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     diarization \u001b[38;5;241m=\u001b[39m pipeline({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muri\u001b[39m\u001b[38;5;124m'\u001b[39m: audio_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m'\u001b[39m: audio_file_path})\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OpenAI' object has no attribute 'Audio'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import environ\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Set your OpenAI API key\n",
    "client.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set your Hugging Face API key\n",
    "HF_API_Key = os.environ[\"HF_API_KEY\"]\n",
    "\n",
    "# Initialize the speaker diarization pipeline\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\")\n",
    "\n",
    "# Path to the directory containing the .wav files\n",
    "wav_directory = \"/Users/shylaatchison/wd/GitHub/Research/Ops-Research/audio_files\"  # Adjust this path as needed\n",
    "\n",
    "def transcribe_audio_with_speaker_diarization(audio_file_path):\n",
    "    # Perform transcription using OpenAI's Whisper\n",
    "    with open(audio_file_path, 'rb') as audio_file:\n",
    "        transcript = client.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "    \n",
    "    # Perform speaker diarization using pyannote.audio\n",
    "    diarization = pipeline({'uri': audio_file_path, 'audio': audio_file_path})\n",
    "\n",
    "    # Combine transcription with speaker labels\n",
    "    transcribed_text = transcript['text']\n",
    "    speaker_segments = []\n",
    "\n",
    "    for segment, track, label in diarization.itertracks(yield_label=True):\n",
    "        speaker_segments.append((segment.start, segment.end, label))\n",
    "    \n",
    "    labeled_transcription = []\n",
    "\n",
    "    for start, end, speaker in speaker_segments:\n",
    "        # Match the speaker segments with the transcription (approximate)\n",
    "        labeled_transcription.append(f\"Speaker {speaker}: {transcribed_text}\")\n",
    "    \n",
    "    return \"\\n\".join(labeled_transcription)\n",
    "\n",
    "def process_wav_files(directory):\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\"_16khz_mono.wav\"):\n",
    "            audio_file_path = os.path.join(directory, file_name)\n",
    "            transcription_file = os.path.splitext(audio_file_path)[0] + \"_transcription.txt\"\n",
    "            \n",
    "            transcription_text = transcribe_audio_with_speaker_diarization(audio_file_path)\n",
    "            \n",
    "            with open(transcription_file, 'w') as f:\n",
    "                f.write(transcription_text)\n",
    "            \n",
    "            print(f\"Transcription saved: {transcription_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_wav_files(wav_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.2.2. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "ename": "APIStatusError",
     "evalue": "Error code: 413 - {'error': {'message': '413: Maximum content size limit (26214400) exceeded (26383212 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIStatusError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscription saved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtranscription_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mprocess_wav_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 53\u001b[0m, in \u001b[0;36mprocess_wav_files\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     50\u001b[0m audio_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, file_name)\n\u001b[1;32m     51\u001b[0m transcription_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(audio_file_path)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_transcription.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 53\u001b[0m transcription_text \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_audio_with_speaker_diarization\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(transcription_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     56\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(transcription_text)\n",
      "Cell \u001b[0;32mIn[20], line 25\u001b[0m, in \u001b[0;36mtranscribe_audio_with_speaker_diarization\u001b[0;34m(audio_file_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranscribe_audio_with_speaker_diarization\u001b[39m(audio_file_path):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Perform transcription using OpenAI's Whisper\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(audio_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m audio_file:\n\u001b[0;32m---> 25\u001b[0m         transcript \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscriptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhisper-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(transcript\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Perform speaker diarization using pyannote.audio\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/standard/lib/python3.11/site-packages/openai/resources/audio/transcriptions.py:114\u001b[0m, in \u001b[0;36mTranscriptions.create\u001b[0;34m(self, file, model, language, prompt, response_format, temperature, timestamp_granularities, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# It should be noted that the actual Content-Type header that will be\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# sent to the server will contain a `boundary` parameter, e.g.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# multipart/form-data; boundary=---abc--\u001b[39;00m\n\u001b[1;32m    113\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultipart/form-data\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/audio/transcriptions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranscription_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTranscriptionCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTranscription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/standard/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/standard/lib/python3.11/site-packages/openai/_base_client.py:936\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    929\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    935\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/standard/lib/python3.11/site-packages/openai/_base_client.py:1040\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1039\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1043\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1044\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1048\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[1;32m   1049\u001b[0m )\n",
      "\u001b[0;31mAPIStatusError\u001b[0m: Error code: 413 - {'error': {'message': '413: Maximum content size limit (26214400) exceeded (26383212 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from pyannote.audio import Pipeline\n",
    "from openai import OpenAI\n",
    "from os import environ\n",
    "\n",
    "# Set your OpenAI API key\n",
    "client.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set your Hugging Face API key (if needed for pyannote)\n",
    "HF_API_Key = os.environ[\"HF_API_KEY\"]\n",
    "\n",
    "# Initialize the speaker diarization pipeline\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\", use_auth_token=HF_API_Key)\n",
    "\n",
    "# Path to the directory containing the .wav files\n",
    "wav_directory = \"/Users/shylaatchison/wd/GitHub/Research/Ops-Research/\"  # Adjust this path as needed\n",
    "\n",
    "audio_file_path = \"/Users/shylaatchison/wd/GitHub/Research/Ops-Research/audio_files/liron_audio_1.wav\"\n",
    "#transcription_file = \"/Users/shylaatchison/wd/GitHub/Research/Ops-Research/transcription_files/liron_audio_1_transcription.txt\"\n",
    "\n",
    "def transcribe_audio_with_speaker_diarization(audio_file_path):\n",
    "    # Perform transcription using OpenAI's Whisper\n",
    "    with open(audio_file_path, 'rb') as audio_file:\n",
    "        transcript = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file)\n",
    "    print(transcript.text)\n",
    "    # Perform speaker diarization using pyannote.audio\n",
    "    diarization = pipeline({'uri': audio_file_path, 'audio': audio_file_path})\n",
    "\n",
    "    # Combine transcription with speaker labels\n",
    "    transcribed_text = transcript['text']\n",
    "    speaker_segments = []\n",
    "\n",
    "    for segment, track, label in diarization.itertracks(yield_label=True):\n",
    "        speaker_segments.append((segment.start, segment.end, label))\n",
    "    \n",
    "    labeled_transcription = []\n",
    "\n",
    "    for start, end, speaker in speaker_segments:\n",
    "        # Match the speaker segments with the transcription (approximate)\n",
    "        labeled_transcription.append(f\"Speaker {speaker}: {transcribed_text}\")\n",
    "    \n",
    "    return \"\\n\".join(labeled_transcription)\n",
    "\n",
    "def process_wav_files(directory):\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\"liron_audio_1.wav\"):\n",
    "            audio_file_path = os.path.join(directory, file_name)\n",
    "            transcription_file = os.path.splitext(audio_file_path)[0] + \"_transcription.txt\"\n",
    "            \n",
    "            transcription_text = transcribe_audio_with_speaker_diarization(audio_file_path)\n",
    "            \n",
    "            with open(transcription_file, 'w') as f:\n",
    "                f.write(transcription_text)\n",
    "            \n",
    "            print(f\"Transcription saved: {transcription_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_wav_files(wav_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "standard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
