{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: brew\n"
     ]
    }
   ],
   "source": [
    "!brew install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/ffmpeg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add the directory containing ffmpeg to the PATH in the notebook\n",
    "os.environ['PATH'] += os.pathsep + '/usr/local/bin'\n",
    "\n",
    "# Check if ffmpeg is now recognized\n",
    "!which ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/ffprobe\n"
     ]
    }
   ],
   "source": [
    "!which ffprobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import environ\n",
    "import yt_dlp\n",
    "import openai\n",
    "from pydub import AudioSegment\n",
    "from pyannote.audio import Pipeline\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Set your OpenAI API key\n",
    "client.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Hugging Face API key\n",
    "HF_API_Key = os.environ[\"HF_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    " # Specify the location of ffmpeg\n",
    "        'ffmpeg_location': '/usr/local/bin/ffmpeg',  # Use the path found via `which ffmpeg`\n",
    "        'outtmpl': output_file\n",
    "```        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/1",
      "[youtube] 1: Downloading webpage\n",
      "[youtube] 1: Downloading ios player API JSON\n",
      "[youtube] 1: Downloading web creator player API JSON\n",
      "[youtube] 1: Downloading m3u8 information\n",
      "[info] 1: Downloading 1 format(s): 251\n",
      "[download] Destination: Title_01.webm\n",
      "[download] 100% of   81.22MiB in 00:00:04 at 19.54MiB/s    \n",
      "[ExtractAudio] Destination: Title_01.wav\n",
      "Deleting original file Title_01.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/7.0.2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[aist#0:0/pcm_s16le @ 0x7fa9fef07a00] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'Title_01.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 01:44:38.54, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'Title_01_16khz_mono.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "[out#0/wav @ 0x7fa9fef082c0] video:0KiB audio:196204KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000039%\n",
      "size=  196204KiB time=01:44:38.53 bitrate= 256.0kbits/s speed=1.28e+03x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Title_02_16khz_mono.wav\n",
      "[youtube] Extracting URL: https://www.youtube.com/2\n",
      "[youtube] 2: Downloading webpage\n",
      "[youtube] 2: Downloading ios player API JSON\n",
      "[youtube] 2: Downloading web creator player API JSON\n",
      "[youtube] 2: Downloading m3u8 information\n",
      "[info] 2: Downloading 1 format(s): 251\n",
      "[download] Destination: Title_02.webm\n",
      "[download] 100% of   45.68MiB in 00:00:02 at 20.48MiB/s    \n",
      "[ExtractAudio] Destination: Title_02.wav\n",
      "Deleting original file Title_02.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/7.0.2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[aist#0:0/pcm_s16le @ 0x7fcdb4f05dc0] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'Title_02.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 00:53:03.04, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'Title_02_16khz_mono.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "size=   77824KiB time=00:41:34.12 bitrate= 255.6kbits/s speed= 989x        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Title_02_16khz_mono.wav\n",
      "[youtube] Extracting URL: https://www.youtube.com/3\n",
      "[youtube] 3: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/wav @ 0x7fcdb58210c0] video:0KiB audio:99470KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000077%\n",
      "size=   99470KiB time=00:53:03.04 bitrate= 256.0kbits/s speed=1.03e+03x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] 3: Downloading ios player API JSON\n",
      "[youtube] 3: Downloading web creator player API JSON\n",
      "[youtube] 3: Downloading m3u8 information\n",
      "[info] 3: Downloading 1 format(s): 251\n",
      "[download] Destination: Title_03.webm\n",
      "[download] 100% of   36.82MiB in 00:00:02 at 14.39MiB/s    \n",
      "[ExtractAudio] Destination: Title_03.wav\n",
      "Deleting original file Title_03l.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/7.0.2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[aist#0:0/pcm_s16le @ 0x7fa28ab0c800] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'Title_03.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 00:46:19.94, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'Title_03_16khz_mono.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "size=   64512KiB time=00:34:30.18 bitrate= 255.3kbits/s speed=1.37e+03x    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Title_03_16khz_mono.wav\n",
      "[youtube] Extracting URL: https://www.youtube.com/4\n",
      "[youtube] 4: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/wav @ 0x7fa28ab0c980] video:0KiB audio:86873KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000088%\n",
      "size=   86873KiB time=00:46:19.93 bitrate= 256.0kbits/s speed=1.37e+03x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] 4: Downloading ios player API JSON\n",
      "[youtube] 4: Downloading web creator player API JSON\n",
      "[youtube] 4: Downloading m3u8 information\n",
      "[info] 4: Downloading 1 format(s): 251\n",
      "[download] Destination: Title_04.webm\n",
      "[download] 100% of   56.88MiB in 00:00:03 at 15.83MiB/s    \n",
      "[ExtractAudio] Destination: Title_04.wav\n",
      "Deleting original file Title_04.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/7.0.2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[aist#0:0/pcm_s16le @ 0x7fbc0b011e00] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'Title_04.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 01:14:42.98, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'Title_04_16khz_mono.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "[out#0/wav @ 0x7fbc0b013e40] video:0KiB audio:140093KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000054%\n",
      "size=  140093KiB time=01:14:42.98 bitrate= 256.0kbits/s speed= 962x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Title_04_16khz_mono.wav\n",
      "[youtube] Extracting URL: https://www.youtube.com/5\n",
      "[youtube] 5: Downloading webpage\n",
      "[youtube] 5: Downloading ios player API JSON\n",
      "[youtube] 5: Downloading web creator player API JSON\n",
      "[youtube] 5: Downloading m3u8 information\n",
      "[info] 5: Downloading 1 format(s): 251\n",
      "[download] Destination: Title_05.webm\n",
      "[download] 100% of   97.54MiB in 00:00:05 at 17.60MiB/s    \n",
      "[ExtractAudio] Destination: Title_05.wav\n",
      "Deleting original file Title_05.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/7.0.2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[aist#0:0/pcm_s16le @ 0x7fb286d07440] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'Title_05.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 02:08:35.40, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'Title_05_16khz_mono.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "[out#0/wav @ 0x7fb286d07300] video:0KiB audio:241106KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000032%\n",
      "size=  241106KiB time=02:08:35.39 bitrate= 256.0kbits/s speed=1.07e+03x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Title_05_16khz_mono.wav\n",
      "[youtube] Extracting URL: https://www.youtube.com/6\n",
      "[youtube] 6: Downloading webpage\n",
      "[youtube] 6: Downloading ios player API JSON\n",
      "[youtube] 6: Downloading web creator player API JSON\n",
      "[youtube] 6: Downloading m3u8 information\n",
      "[info] 6: Downloading 1 format(s): 251\n",
      "[download] Destination: Title_06.webm\n",
      "[download] 100% of  225.71MiB in 00:00:10 at 21.86MiB/s    \n",
      "[ExtractAudio] Destination: Title_06.wav\n",
      "Deleting original file Title_06.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/7.0.2 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "[aist#0:0/pcm_s16le @ 0x7fef6800bf00] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'Title_06.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 03:51:16.96, bitrate: 1536 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'Title_06_16khz_mono.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.1.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.3.100 pcm_s16le\n",
      "[out#0/wav @ 0x7fef6800be00] video:0KiB audio:433655KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000018%\n",
      "size=  433655KiB time=03:51:16.96 bitrate= 256.0kbits/s speed=1.01e+03x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Title_06_16khz_mono.wav\n",
      "All videos processed!\n"
     ]
    }
   ],
   "source": [
    "import yt_dlp\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "urls = [\n",
    "        \"https://www.youtube.com/1"\n",
    "        \"https://www.youtube.com/2"\n",
    "        \"https://www.youtube.com/3\"\n",
    "        \"https://www.youtube.com/4\"\n",
    "        \"https://www.youtube.com/5\"\n",
    "        \"https://www.youtube.com/6\"\n",
    "    ]\n",
    "\n",
    "def download_and_convert(url):\n",
    "    try:\n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'postprocessors': [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'wav',\n",
    "            }],\n",
    "            'outtmpl': '%(title)s.%(ext)s',\n",
    "        }\n",
    "\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            info = ydl.extract_info(url, download=True)\n",
    "            filename = ydl.prepare_filename(info).replace('.webm', '.wav')\n",
    "\n",
    "        # Convert to 16kHz mono\n",
    "        output_filename = f\"{os.path.splitext(filename)[0]}_16khz_mono.wav\"\n",
    "        cmd = [\n",
    "            \"ffmpeg\",\n",
    "            \"-i\", filename,\n",
    "            \"-ar\", \"16000\",\n",
    "            \"-ac\", \"1\",\n",
    "            \"-c:a\", \"pcm_s16le\",\n",
    "            output_filename\n",
    "        ]\n",
    "        subprocess.run(cmd, check=True)\n",
    "\n",
    "        # Clean up original WAV file\n",
    "        os.remove(filename)\n",
    "\n",
    "        print(f\"Processed: {output_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {url}: {str(e)}\")\n",
    "\n",
    "for url in urls:\n",
    "    download_and_convert(url)\n",
    "\n",
    "print(\"All videos processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not download 'pyannote/speaker-diarization' pipeline.\n",
      "It might be because the pipeline is private or gated so make\n",
      "sure to authenticate. Visit https://hf.co/settings/tokens to\n",
      "create your access token and retry with:\n",
      "\n",
      "   >>> Pipeline.from_pretrained('pyannote/speaker-diarization',\n",
      "   ...                          use_auth_token=YOUR_AUTH_TOKEN)\n",
      "\n",
      "If this still does not work, it might be because the pipeline is gated:\n",
      "visit https://hf.co/pyannote/speaker-diarization to accept the user conditions.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OpenAI' object has no attribute 'Audio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscription saved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtranscription_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 58\u001b[0m     \u001b[43mprocess_wav_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 50\u001b[0m, in \u001b[0;36mprocess_wav_files\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     47\u001b[0m audio_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, file_name)\n\u001b[1;32m     48\u001b[0m transcription_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(audio_file_path)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_transcription.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 50\u001b[0m transcription_text \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_audio_with_speaker_diarization\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(transcription_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     53\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(transcription_text)\n",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m, in \u001b[0;36mtranscribe_audio_with_speaker_diarization\u001b[0;34m(audio_file_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranscribe_audio_with_speaker_diarization\u001b[39m(audio_file_path):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Perform transcription using OpenAI's Whisper\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(audio_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m audio_file:\n\u001b[0;32m---> 24\u001b[0m         transcript \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAudio\u001b[49m\u001b[38;5;241m.\u001b[39mtranscribe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhisper-1\u001b[39m\u001b[38;5;124m\"\u001b[39m, audio_file)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Perform speaker diarization using pyannote.audio\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     diarization \u001b[38;5;241m=\u001b[39m pipeline({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muri\u001b[39m\u001b[38;5;124m'\u001b[39m: audio_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m'\u001b[39m: audio_file_path})\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OpenAI' object has no attribute 'Audio'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import environ\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Set your OpenAI API key\n",
    "client.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set your Hugging Face API key\n",
    "HF_API_Key = os.environ[\"HF_API_KEY\"]\n",
    "\n",
    "# Initialize the speaker diarization pipeline\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\")\n",
    "\n",
    "# Path to the directory containing the .wav files\n",
    "wav_directory = \"~/wd/GitHub/Research/Ops-Research/audio_files\"  # Adjust this path as needed\n",
    "\n",
    "def transcribe_audio_with_speaker_diarization(audio_file_path):\n",
    "    # Perform transcription using OpenAI's Whisper\n",
    "    with open(audio_file_path, 'rb') as audio_file:\n",
    "        transcript = client.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "    \n",
    "    # Perform speaker diarization using pyannote.audio\n",
    "    diarization = pipeline({'uri': audio_file_path, 'audio': audio_file_path})\n",
    "\n",
    "    # Combine transcription with speaker labels\n",
    "    transcribed_text = transcript['text']\n",
    "    speaker_segments = []\n",
    "\n",
    "    for segment, track, label in diarization.itertracks(yield_label=True):\n",
    "        speaker_segments.append((segment.start, segment.end, label))\n",
    "    \n",
    "    labeled_transcription = []\n",
    "\n",
    "    for start, end, speaker in speaker_segments:\n",
    "        # Match the speaker segments with the transcription (approximate)\n",
    "        labeled_transcription.append(f\"Speaker {speaker}: {transcribed_text}\")\n",
    "    \n",
    "    return \"\\n\".join(labeled_transcription)\n",
    "\n",
    "def process_wav_files(directory):\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\"_16khz_mono.wav\"):\n",
    "            audio_file_path = os.path.join(directory, file_name)\n",
    "            transcription_file = os.path.splitext(audio_file_path)[0] + \"_transcription.txt\"\n",
    "            \n",
    "            transcription_text = transcribe_audio_with_speaker_diarization(audio_file_path)\n",
    "            \n",
    "            with open(transcription_file, 'w') as f:\n",
    "                f.write(transcription_text)\n",
    "            \n",
    "            print(f\"Transcription saved: {transcription_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_wav_files(wav_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.2.2. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "ename": "APIStatusError",
     "evalue": "Error code: 413 - {'error': {'message': '413: Maximum content size limit (26214400) exceeded (26383212 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIStatusError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscription saved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtranscription_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mprocess_wav_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 53\u001b[0m, in \u001b[0;36mprocess_wav_files\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     50\u001b[0m audio_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, file_name)\n\u001b[1;32m     51\u001b[0m transcription_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(audio_file_path)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_transcription.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 53\u001b[0m transcription_text \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_audio_with_speaker_diarization\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(transcription_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     56\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(transcription_text)\n",
      "Cell \u001b[0;32mIn[20], line 25\u001b[0m, in \u001b[0;36mtranscribe_audio_with_speaker_diarization\u001b[0;34m(audio_file_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranscribe_audio_with_speaker_diarization\u001b[39m(audio_file_path):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Perform transcription using OpenAI's Whisper\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(audio_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m audio_file:\n\u001b[0;32m---> 25\u001b[0m         transcript \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscriptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhisper-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(transcript\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Perform speaker diarization using pyannote.audio\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/standard/lib/python3.11/site-packages/openai/resources/audio/transcriptions.py:114\u001b[0m, in \u001b[0;36mTranscriptions.create\u001b[0;34m(self, file, model, language, prompt, response_format, temperature, timestamp_granularities, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# It should be noted that the actual Content-Type header that will be\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# sent to the server will contain a `boundary` parameter, e.g.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# multipart/form-data; boundary=---abc--\u001b[39;00m\n\u001b[1;32m    113\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultipart/form-data\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/audio/transcriptions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranscription_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTranscriptionCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTranscription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/standard/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/standard/lib/python3.11/site-packages/openai/_base_client.py:936\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    929\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    935\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/standard/lib/python3.11/site-packages/openai/_base_client.py:1040\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1039\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1043\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1044\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1048\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[1;32m   1049\u001b[0m )\n",
      "\u001b[0;31mAPIStatusError\u001b[0m: Error code: 413 - {'error': {'message': '413: Maximum content size limit (26214400) exceeded (26383212 bytes read)', 'type': 'server_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from pyannote.audio import Pipeline\n",
    "from openai import OpenAI\n",
    "from os import environ\n",
    "\n",
    "# Set your OpenAI API key\n",
    "client.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Set your Hugging Face API key (if needed for pyannote)\n",
    "HF_API_Key = os.environ[\"HF_API_KEY\"]\n",
    "\n",
    "# Initialize the speaker diarization pipeline\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\", use_auth_token=HF_API_Key)\n",
    "\n",
    "# Path to the directory containing the .wav files\n",
    "wav_directory = \"~/wd/GitHub/Research/Ops-Research/\"  # Adjust this path as needed\n",
    "\n",
    "audio_file_path = \"~/wd/GitHub/Research/Ops-Research/audio_files/liron_audio_1.wav\"\n",
    "#transcription_file = \"~/wd/GitHub/Research/Ops-Research/transcription_files/liron_audio_1_transcription.txt\"\n",
    "\n",
    "def transcribe_audio_with_speaker_diarization(audio_file_path):\n",
    "    # Perform transcription using OpenAI's Whisper\n",
    "    with open(audio_file_path, 'rb') as audio_file:\n",
    "        transcript = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file)\n",
    "    print(transcript.text)\n",
    "    # Perform speaker diarization using pyannote.audio\n",
    "    diarization = pipeline({'uri': audio_file_path, 'audio': audio_file_path})\n",
    "\n",
    "    # Combine transcription with speaker labels\n",
    "    transcribed_text = transcript['text']\n",
    "    speaker_segments = []\n",
    "\n",
    "    for segment, track, label in diarization.itertracks(yield_label=True):\n",
    "        speaker_segments.append((segment.start, segment.end, label))\n",
    "    \n",
    "    labeled_transcription = []\n",
    "\n",
    "    for start, end, speaker in speaker_segments:\n",
    "        # Match the speaker segments with the transcription (approximate)\n",
    "        labeled_transcription.append(f\"Speaker {speaker}: {transcribed_text}\")\n",
    "    \n",
    "    return \"\\n\".join(labeled_transcription)\n",
    "\n",
    "def process_wav_files(directory):\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\"liron_audio_1.wav\"):\n",
    "            audio_file_path = os.path.join(directory, file_name)\n",
    "            transcription_file = os.path.splitext(audio_file_path)[0] + \"_transcription.txt\"\n",
    "            \n",
    "            transcription_text = transcribe_audio_with_speaker_diarization(audio_file_path)\n",
    "            \n",
    "            with open(transcription_file, 'w') as f:\n",
    "                f.write(transcription_text)\n",
    "            \n",
    "            print(f\"Transcription saved: {transcription_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_wav_files(wav_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "standard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
